{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3d1243",
   "metadata": {},
   "source": [
    "# 1. Create PGD Adversarial Flickr Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0c5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(pretrained_model, image, epsilon = 0.1):\n",
    "    adv_img = projected_gradient_descent(pretrained_model, image, epsilon, \n",
    "                                                              eps_iter = 0.01, nb_iter = 40, norm = np.inf)\n",
    "    # true label\n",
    "    outputs1 = pretrained_model(image.cuda())\n",
    "    _, preds1 = torch.max(outputs1, 1)\n",
    "    key1 = str(preds1.detach().cpu().numpy()[0])\n",
    "    \n",
    "    # adversarial label\n",
    "    outputs2 = pretrained_model(adv_img.cuda())\n",
    "    _, preds2 = torch.max(outputs2, 1)\n",
    "    key2 = str(preds2.detach().cpu().numpy()[0])\n",
    "    \n",
    "    return adv_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c3f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir ./data/pgdAttackFlickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd4c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate flickr adversarial examples\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "\n",
    "import glob\n",
    "\n",
    "path = './data/Images'\n",
    "subset = glob.glob(path+'/*')\n",
    "all_images = []\n",
    "pretrained_model = models.resnet101(pretrained=True).cuda()\n",
    "pretrained_model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# count = 0\n",
    "# total = 0\n",
    "# for img in tqdm(subset):\n",
    "#     name = img.split('/')[3]\n",
    "#     image = Image.open(img).convert('RGB')\n",
    "#     image = preprocess(image)\n",
    "#     result = torch.unsqueeze(image, 0)\n",
    "#     adv_img = attack(pretrained_model, result.cuda())\n",
    "#     save_image(adv_img, './data/pgdAttackFlickr/'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e3d73",
   "metadata": {},
   "source": [
    "# 2. Create FGSM Adversarial Flickr Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ee9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(pretrained_model, image, epsilon = 0.1):\n",
    "    adv_img = fast_gradient_method(pretrained_model, image, epsilon, norm = np.inf)\n",
    "    # true label\n",
    "    outputs1 = pretrained_model(image.cuda())\n",
    "    _, preds1 = torch.max(outputs1, 1)\n",
    "    key1 = str(preds1.detach().cpu().numpy()[0])\n",
    "    \n",
    "    # adversarial label\n",
    "    outputs2 = pretrained_model(adv_img.cuda())\n",
    "    _, preds2 = torch.max(outputs2, 1)\n",
    "    key2 = str(preds2.detach().cpu().numpy()[0])\n",
    "    \n",
    "    return adv_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2213c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ./data/fgsmAttackFlickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaff6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate flickr adversarial examples\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "from cleverhans.torch.attacks.fast_gradient_method import (\n",
    "    fast_gradient_method,\n",
    ")\n",
    "\n",
    "import glob\n",
    "\n",
    "path = './data/Images'\n",
    "subset = glob.glob(path+'/*')\n",
    "all_images = []\n",
    "pretrained_model = models.resnet101(pretrained=True).cuda()\n",
    "pretrained_model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# count = 0\n",
    "# total = 0\n",
    "# for img in tqdm(subset):\n",
    "#     name = img.split('/')[3]\n",
    "#     image = Image.open(img).convert('RGB')\n",
    "#     image = preprocess(image)\n",
    "#     result = torch.unsqueeze(image, 0)\n",
    "#     adv_img = attack(pretrained_model, result.cuda())\n",
    "#     save_image(adv_img, './data/fgsmAttackFlickr/'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba42d58",
   "metadata": {},
   "source": [
    "# 3. Finetune Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb3a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class image_title_dataset(Dataset):\n",
    "    def __init__(self, list_image_path,list_txt, attack):\n",
    "\n",
    "        self.image_path = list_image_path\n",
    "        self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
    "        self.attack = attack\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if(self.attack==\"pgd\"):\n",
    "            folder = \"pgdAttackFlickr\"\n",
    "        else:\n",
    "            folder = \"fgsmAttackFlickr\"\n",
    "        \n",
    "        image = Image.open(\"./data/\"+folder+\"/\"+self.image_path[idx]).convert('RGB')\n",
    "        image = preprocess(image)\n",
    "        #image = preprocess(Image.open(self.image_path[idx])) # Image from PIL module\n",
    "        title = self.title[idx]\n",
    "        return image,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe7667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d505bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgMeter:\n",
    "    def __init__(self, name=\"Metric\"):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg, self.sum, self.count = [0] * 3\n",
    "\n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += val * count\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __repr__(self):\n",
    "        text = f\"{self.name}: {self.avg:.4f}\"\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a881f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_valid_dfs():\n",
    "    dataframe = pd.read_csv(\"data/captions.txt\")\n",
    "    dataframe.insert(0, 'id', range(0, len(dataframe)))\n",
    "    max_id = dataframe[\"id\"].max() + 1\n",
    "\n",
    "    image_ids = np.arange(0, max_id)\n",
    "    np.random.seed(42)\n",
    "    valid_ids = np.random.choice(\n",
    "        image_ids, size=int(0.05 * len(image_ids)), replace=False\n",
    "    )\n",
    "    train_ids = [id_ for id_ in image_ids if id_ not in valid_ids]\n",
    "    train_dataframe = dataframe[dataframe[\"id\"].isin(train_ids)].reset_index(drop=True)\n",
    "    valid_dataframe = dataframe[dataframe[\"id\"].isin(valid_ids)].reset_index(drop=True)\n",
    "    return train_dataframe, valid_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ebb8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim \n",
    "import numpy as np\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "def write_logs(file_name, message):\n",
    "    f = open(file_name, \"a\")\n",
    "    f.write(message + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "def train(df, lr= 5e-5, noise=None, epochs=10, batch_size=64, attack = None):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "    model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "    if noise is not None:\n",
    "        preprocess.transforms.append(AddGaussianNoise(0, noise))\n",
    "    loss_img = nn.CrossEntropyLoss()\n",
    "    loss_txt = nn.CrossEntropyLoss()\n",
    "    #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "    optimizer = optim.Adam(model.parameters(), lr ,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) \n",
    "    \n",
    "    list_image_path = df['image'].values\n",
    "    list_txt = df['caption'].values\n",
    "    dataset = image_title_dataset(list_image_path,list_txt, attack)\n",
    "    train_dataloader = DataLoader(dataset,batch_size = batch_size) #Define your own dataloader\n",
    "    best_loss = float(\"inf\")\n",
    "    log_file_name = attack+\"_train_logs\"\n",
    "    for epoch in tqdm(range(epochs), total=epochs):\n",
    "        loss_meter = AvgMeter()\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            images, texts = batch \n",
    "            images = images.to(device)\n",
    "            texts = texts.to(device)\n",
    "            logits_per_image, logits_per_text = model(images, texts)\n",
    "            ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "            total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "            total_loss.backward()\n",
    "            count = images.size(0)\n",
    "            loss_meter.update(total_loss.item(), count)\n",
    "            \n",
    "            if device == \"cpu\":\n",
    "                optimizer.step()\n",
    "            else: \n",
    "                convert_models_to_fp32(model)\n",
    "                optimizer.step()\n",
    "                clip.model.convert_weights(model)\n",
    "            \n",
    "        if loss_meter.avg < best_loss:\n",
    "            best_loss= loss_meter.avg\n",
    "            torch.save(model.state_dict(), f\"adv_trained_{attack}_best2.pt\")\n",
    "            print(\"Saved Best Model!\")\n",
    "            \n",
    "        write_logs(log_file_name, f\"{epoch}, {loss_meter.avg:.5f}, {best_loss:.5f}\")             \n",
    "        print(f\"Epoch: {epoch + 1}, train_loss: {loss_meter.avg:.5f}, best_loss: {best_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a83ec6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2022, 3)\n",
      "Adversarial training on pgd dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▌                                                 | 1/10 [00:16<02:31, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 1, train_loss: 1.72762, best_loss: 1.72762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████                                            | 2/10 [00:33<02:16, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 2, train_loss: 0.68656, best_loss: 0.68656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████▌                                      | 3/10 [00:50<01:57, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 3, train_loss: 0.63578, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████                                 | 4/10 [01:04<01:35, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss: 0.67379, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▌                           | 5/10 [01:19<01:16, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train_loss: 0.82499, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████                      | 6/10 [01:33<00:59, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train_loss: 0.86654, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████▌                | 7/10 [01:47<00:44, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, train_loss: 0.89214, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████           | 8/10 [02:02<00:29, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, train_loss: 1.02211, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████▌     | 9/10 [02:16<00:14, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, train_loss: 1.05077, best_loss: 0.63578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 10/10 [02:30<00:00, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train_loss: 1.11250, best_loss: 0.63578\n",
      "Adversarial training on fgsm dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████▌                                                 | 1/10 [00:16<02:31, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 1, train_loss: 1.82509, best_loss: 1.82509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████                                            | 2/10 [00:33<02:15, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 2, train_loss: 0.69792, best_loss: 0.69792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████▌                                      | 3/10 [00:50<01:58, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 3, train_loss: 0.61778, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████                                 | 4/10 [01:05<01:35, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss: 0.68396, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▌                           | 5/10 [01:19<01:17, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train_loss: 0.79556, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████                      | 6/10 [01:34<01:00, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train_loss: 0.86293, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████▌                | 7/10 [01:48<00:44, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, train_loss: 0.86170, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████           | 8/10 [02:02<00:29, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, train_loss: 1.12028, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████▌     | 9/10 [02:17<00:14, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, train_loss: 1.05675, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 10/10 [02:31<00:00, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train_loss: 1.19895, best_loss: 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataframe, valid_dataframe = make_train_valid_dfs()\n",
    "print(valid_dataframe.shape)\n",
    "\n",
    "\n",
    "for att in [\"pgd\", \"fgsm\"]:\n",
    "    print(f\"Adversarial training on {att} dataset\")\n",
    "    train(valid_dataframe, 5e-5, epochs= 10, attack = att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2dd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
